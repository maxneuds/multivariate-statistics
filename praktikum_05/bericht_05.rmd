---
output: pdf_document
header-includes: 
- \usepackage[utf8]{inputenc}
- \usepackage[T1]{fontenc}
- \usepackage[ngerman]{babel}
- \usepackage{amsmath,amssymb,amsthm}
- \usepackage{dsfont}
- \usepackage{listings}
- \usepackage{floatrow}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- '\fancyhead[C,C]{Gruppe 5: Robin Baudisch, Merlin Kopfmann, Maximilian Neudert}'
- \fancyhead[L]{}
- \fancyhead[R]{}
- \fancyfoot[C,C]{\thepage}
- \renewcommand{\footrulewidth}{0.4pt}
- \newcommand{\cov}{\operatorname{Cov}}
- \newcommand{\cor}{\operatorname{Cor}}
- \newcommand{\V}{\mathbf{\operatorname{V}}}
- \newcommand{\E}{\mathbf{\operatorname{E}}}
---

<style type="text/css">
body{
  font-size: 12px;
}
h1 {
  font-size: 18px;
}
h1 {
  font-size: 14px;
}
h1 {
  font-size: 12px;
}
</style>

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,     # Keep compiling upon error
                      collapse=TRUE,  # collapse by default
                      echo=TRUE,      # echo code by default
                      comment = "#>", # change comment character
                      warning=TRUE,   # show R warnings
                      message=FALSE,  # show R messages
                      out.width = "100%",
                      out.height = "100%",
                      fig.width = 10)
```

<!---** Hochschule Darmstadt | Studiengang Data Science | Sommersemester 2019 **--->

```{r}
set.seed(42)
```

# Arbeitsblatt 5

## Aufgabe 1

Erinnerung. Wir nehmen die Gauss-Markov-Annahmen an (Fehlerterme haben Erwartungswert 0, gleiche Varianz und sind unkorreliert) und folglich gilt:

\begin{align*}
& \cov(\epsilon_i, \epsilon_j) = 0 \quad \forall i \neq j \\
& \E(\epsilon_i) = \theta\\
& \V(\epsilon_i) = \sigma^2\\
& Y_i = X_i b + \epsilon_i\\
& \hat Y_i = (X \hat b)_i\\
& \hat b = (X^T X)^{-1} X^T Y\\
& \hat b_i = \left((X^T X)^{-1} X^T Y\right)_i\\
& H = X (X^T X)^{-1} X^T\\
& H = H \cdot H\\
& H = H^T
\end{align*}
$X_i$ ist hier eine Zeile der Designmatrix und $H_i$ eine Zeile der Hatmatrix.
Zuerst stellen wir fest, dass $X_i b$ und $\epsilon_i$ unabhängig voneinander sind und $X_i b$ varianzlos ist. Dann erhalten wir
\begin{align*}
\V(Y_i) = \V(X_i b + \epsilon_i) = \V(X_i b) + \V(\epsilon_i) = \sigma^2.
\end{align*}
Ferner können wir berechnen
\begin{align*}
\V (\hat Y_i)
& = \V((X \hat b)_i )
= \V((H Y)_i)
= H_i \V(Y) H_i^T
= H_i \V(X b + \epsilon) H_i^T \\
& = H_i \operatorname{diag}(\sigma^2) H_i^T 
= h_{ii} \sigma^2.
\end{align*}

Ähnlich können wir berechnen

\begin{align*}
\cov(Y_i, \hat Y_i)
& = \cov(Y_i, H_i Y) \\
& = H_i \cov(x_i b + \epsilon_i, (X b + \epsilon)_i) H_i^T \\
& = h_{ii} \sigma^2.
\end{align*}

Und schließlich erhalten wir durch Einsetzen 

\begin{align*}
\cor(Y_i, \hat Y_i)
& = \frac{
  \cov(Y_i, \hat Y_i)
}{
  \sqrt{\V(Y_i) \V(\hat Y_i)}
} \\
& = \frac{
  h_{ii} \sigma^2
}{
  \sqrt{\sigma^2 h_{ii} \sigma^2}
} \\
& = \sqrt{h_{ii}}.
\end{align*}

## Aufgabe 2

```{r}
library("ISLR")
model_mpg <- lm(mpg~horsepower+year+origin, data = Auto)
plot(model_mpg)
```
\newpage
```{r}
model_log_mpg <- lm(log(mpg)~horsepower+year+origin, data = Auto)
plot(model_log_mpg)
```

### a)

Wenn wir uns die Grafik "Residuals vs Fitted" ansehen, sehen wir, dass die Daten kein offensichtliches, eindeutiges Muster haben. Obwohl die Kurven leicht gewölbt sind, haben sie gleichmäßige Residuen um die horizontale Linie herum verteilt, ohne ein ausgeprägtes Muster.
Dies ist ein guter Hinweis darauf, dass es sich nicht um eine nichtlineare Beziehung handelt.

Die Residuen sollten normalverteilt sein, und der Q-Q Plot ist ein gutes Instrument, um dies zu überprüfen. Für beide Modelle zeigt der Q-Q-Plot eine ziemlich gute Anpassung auf die Linie. Nach oben hin weichen die Punkte für das mpg-Modell deutlicher von der Linie ab, als im log(mpg)-Modell. 

Die "Scale-Location"-Plots testen die lineare Regressionsannahme der gleichen Varianz (Homoscedastizität), d.h. dass die Residuen die gleiche Varianz entlang der Regressionslinie aufweisen.

In unseren beiden Modellen sind die Residuen relativ gut über und unter einer ziemlich horizontalen Linie verteilt.

Die "Residuals vs Leverage"-Plots können verwendet werden, um einflussreiche Datenpunkte im Datensatz zu finden. Ein einflussreicher Datenpunkt ist einer, der, wenn er entfernt wird, das Modell beeinflusst, so dass seine Einbeziehung oder sein Ausschluss in Betracht gezogen werden sollte.

Ein einflussreicher Datenpunkt kann ein Ausreißer sein oder auch nicht, und der Zweck dieser Grafik ist es, Fälle zu identifizieren, die einen hohen Einfluss auf das Modell haben. Ausreißer neigen dazu, Leverage und damit Einfluss auf das Modell auszuüben.

Ein einflussreicher Fall erscheint oben rechts oder unten links in der Grafik innerhalb einer roten Linie, die Cook's Distance markiert. 

In beiden Modellen gibt es keine offensichtlichen Ausreißer (laut Cook's Distance).

Abschließend würden wir das log(mpg)-Modell bevorzugen, obwohl es kaum Unterschiede in den Residuen gibt. Alleine der Q-Q-Plot des log(mpg)-Modells deutet auf eine bessere Anpassung der Residuen auf die Normalverteilung hin als im mpg-Modell.

### b)

Der Punkt 116 ist in beiden Modellen des Öfteren markiert. Schauen wir uns diesen näher an:

```{r}
pt_116 <- Auto[116,]
summary <- summary(Auto)
c(pt_116)
summary
```

Hier wird deutlich, dass der Punkt 116 ein Extremfall in unserem Datensatz ist.

### c)

```{r}
library(leaps)
regfit.full = regsubsets(log(mpg)~cylinders+displacement+horsepower
                         +weight+acceleration+year+origin, data=Auto)
reg.summary = summary(regfit.full)
```

```{r}
plot(reg.summary$bic, xlab="Number of Variables", ylab="BIC", type="l") 
plot(reg.summary$cp, xlab="Number of Variables", ylab="AIC", type="l")
plot(reg.summary$rsq, xlab="Number of Variables", ylab="RSq", type="l")
```
BIC:

- BIC wird für das Modell mit nur 4 Kovariaten minimal.

AIC:

- Nach AIC ist die Entscheidungsfindung nicht ganz so eindeutig. Auch hier ist bei 4 Kovariaten der AIC sehr gering, jedoch steigt der AIC bei wachsender Anzahl an Kovariaten nicht mehr an, sinkt aber auch nicht deutlich weiter. 

$R^2:$

- Ein hohes $R^2$ spricht für ein gutes Modell. Allerdings gibt es, anders als bei AIC und BIC, keinen Strafterm, welcher die Anzahl an Kovariaten "bestraft". Deshalb steigt das $R^2$ mit Anzahl der Kovariaten (leicht) an.


Wir würden uns für ein Modell mit 4 Kovariaten entscheiden, da dort BIC und AIC sehr klein sind und $R^2$ groß ist. 

```{r}
coef(regfit.full, 4)
```

### d)

```{r}
library(car)
model_all_log <- lm(log(mpg)~cylinders+displacement+horsepower+
                      weight+acceleration+year+origin, data=Auto)

model_4_log <- lm(log(mpg)~horsepower+weight+year+origin, data=Auto)
vif(model_all_log)
cat("\n")
vif(model_4_log)
```

Schaut man sich die VIF-Werte an, wird deutlich, dass im Modell mit allen Kovariaten definitiv Multikollinearität ein Problem darstellt.

Im Modell, dass wir durch die Subset-Selektion gefunden haben, sind die VIF-Werte geringer. "Pi-Mal-Daumen" ist die Faustregel:

- 1 = unkorreliert

- zwischen 1 und 5 = moderat korreliert

- größer 5 = stark korreliert

Die VIF-Werte für horsepower und weight liegen beide bei circa 5. Nimmt man nun die Kovariate mit dem höchsten VIF-Wert aus dem Modell heraus, ergeben sich folgende VIF-Werte für das neue Modell:


```{r}
model_3_log <- lm(log(mpg)~horsepower+year+origin, data=Auto)
vif(model_3_log)
```

Eindeutig wird der Einfluss von weight durch horsepower bereits gut "erklärt". Die VIF-Werte liegen nun im annehmbaren Bereich. Das Modell mit horsepower, year und origin scheint das robustere zu sein. 

\newpage
## Aufgabe 3

### a)

Likelihood-Ratio-Test:

&nbsp;
&nbsp;

Schätzstatistik: 

$T = 2\cdot(LL_M2 - LL_M1) \sim_{H0} \chi^2_q \quad$, q = Anzahl zusätzlicher Parameter im komplexeren Modell

Hier: 

$T = 2\cdot(LL_M2 - LL_M1) \sim_{H0} \chi^2_{1}$ mit $\alpha = 0.1572992$

$\Rightarrow \quad X_{p+1}$ wird in das Modell aufgenommen, wenn gilt:

&nbsp;
&nbsp;

$T = 2\cdot(LL_{M2} - LL_{M1}) > 2$, da  

$\chi^2_{1_{(1-0.1572992)}} = 2$  

&nbsp;
&nbsp;

AIC-Vergleich:

&nbsp;
&nbsp;

$AIC = -2LL + 2k \quad$, k = Anzahl Modellparameter

$AIC_{M1} = -2LL_{M1} + 2\cdot p \quad$ 

$AIC_{M2} = -2LL_{M2} + 2\cdot(p+1)$ 

$\Rightarrow \quad X_{p+1}$ wird in das Modell aufgenommen, wenn gilt:

&nbsp;

$AIC_{M1} - AIC_{M2} > 0$

&nbsp;

$= (-2LL_{M1}+2p) -  (-2LL_{M2}+2(p+1)) > 0$

&nbsp;

$= -2LL_{M1} + 2p + 2LL_{M2} - 2p - 2 > 0$

&nbsp;

$= -2(LL_{M1} - LL_{M2} - p + p + 1) > 0$

&nbsp;

$= -2(LL_{M1} - LL_{M2} + 1 > 0$

&nbsp;

$= 2(-LL_{M1} + LL_{M2} - 1) > 0$

&nbsp;

$= 2(LL_{M2} - LL_{M1} - 1) > 0$

&nbsp;

$= 2(LL_{M2} - LL_{M1}) - 2 > 0$

&nbsp;

$= 2(LL_{M2} - LL_{M1}) > 2$

### b)
Modellvergleich: log(mpg) ~ acceleration (model_1) vs log(mpg) ~ acceleration+horsepower (model_2)
```{r}
library(lmtest)
model_1 = lm(log(mpg)~acceleration, data=Auto)
model_2 = lm(log(mpg)~acceleration+horsepower, data=Auto)
AIC(model_1)
AIC(model_2)
lmtest::lrtest(model_1, model_2)
```

model_2 ist sowohl im AIC-Vergleich als auch nach Likelihood-Ratio-Test besser als model_1. 