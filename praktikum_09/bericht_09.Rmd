---
output: pdf_document
header-includes: 
- \usepackage[utf8]{inputenc}
- \usepackage[T1]{fontenc}
- \usepackage[ngerman]{babel}
- \usepackage{amsmath,amssymb,amsthm}
- \usepackage{dsfont}
- \usepackage{listings}
- \usepackage{floatrow}
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- '\fancyhead[C,C]{Gruppe 11: Robin Baudisch, Merlin Kopfmann, Maximilian Neudert}'
- \fancyhead[L]{}
- \fancyhead[R]{}
- \fancyfoot[C,C]{\thepage}
- \renewcommand{\footrulewidth}{0.4pt}
- '\newcommand{\cov}[1]{\operatorname{Cov}\left( #1 \right)}'
- '\newcommand{\cor}[1]{\operatorname{Cor}\left( #1 \right)}'
- '\newcommand{\V}[1]{\mathbf{\operatorname{V}}\left( #1 \right)}'
- '\newcommand{\E}[1]{\mathbf{\operatorname{E}}\left( #1 \right)}'
---

<style type="text/css">
body{
  font-size: 12px;
}
h1 {
  font-size: 18px;
}
h1 {
  font-size: 14px;
}
h1 {
  font-size: 12px;
}
</style>

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,     # Keep compiling upon error
                      collapse=TRUE,  # collapse by default
                      echo=TRUE,      # echo code by default
                      comment = "#>", # change comment character
                      warning=TRUE,   # show R warnings
                      message=FALSE,  # show R messages
                      out.width = "100%",
                      out.height = "100%",
                      fig.width = 10)

packageTest<- function(x)  {
    if (!require(x,character.only = TRUE))  {
      install.packages(x,dep=TRUE)
      if(!require(x,character.only = TRUE)) stop("Package not found")
    }
}
```

<!---** Hochschule Darmstadt | Studiengang Data Science | Sommersemester 2019 **--->

```{r}
set.seed(42)
```

# Arbeitsblatt 9

## Aufgabe 1
Unterschiede hinsichtlich

  * der Voraussetzungen an die Zielvariable:
      Bei Diskriminanzanalyse und KNN auch Multilabel-Classification möglich, bei logistischer Regression nur Binary-Classification.
      
  * den Voraussetzungen an die Einflussvariablen:
      Bei logistischer Regression und KNN keine Normalverteilungsannahme der Einflussvariablen nötig, bei Diskriminanzanalyse schon.
  
  * der resultierenden Klassifikationsgrenzen:
      Bei logistischer Regression und KNN sind Klassifikationsgrenzen interpretierbar, da es sich um geschätzte Wahrscheinlichkeiten handelt, bei        Diskriminanzanalyse ist eine Interpretation nicht möglich.
      
  * den Konsequenzen einer Standardisierung von Einflussvariablen:
      Bei KNN ist eine Standardisierung nötig (nur hilfreich?), da Distanzmaße skalenabhängig sind, logistische Regression und Diskriminanzanalyse sind skalenunabhängig.

## Aufgabe 2

### a)

```{r}
load("diab.RData")

log_reg <- glm(diabetes~pgc+bmi, family=binomial(link='logit'), data=diab)

pred = predict.glm(log_reg, data.frame(pgc=120, bmi=27), type="response")[1]
pred = as.vector(pred)

logit = function(L) {
  return(1/2*(1+tanh(L/2)))
}

pred2 = as.vector(logit(log_reg$coefficients[1]+log_reg$coefficients[2]
                        *120+log_reg$coefficients[3]*27))
delta = round((pred - pred2)^2, 4)
delta

pred
pred2
```

### b)
```{r}
summary(log_reg)
```

Die Koeffizientenschätzung der Variablen pgc ist $\beta$ = `r log_reg$coefficients[2]`, ein positiver Wert. Dies bedeutet, dass ein Anstieg der Glukosekonzentration mit einer Erhöhung der Wahrscheinlichkeit verbunden ist, an Diabetes erkrankt zu sein.

### c)
Ein wichtiges zu verstehendes Konzept für die Interpretation der logistischen Beta-Koeffizienten ist die Odds Ratio. Die Odds Ratio misst die Zuordnung zwischen einer Prädiktorvariablen (x) und der Ergebnisvariablen (y). Es stellt das Verhältnis der Chancen dar, dass ein Ereignis eintritt (Ereignis = 1) bei Vorhandensein des Prädiktors x (x = 1), verglichen mit den Chancen des Ereignisses, das in Abwesenheit dieses Prädiktors eintritt (x = 0).

Für einen gegebenen Prädiktor (z.B. x1) entspricht der zugehörige Beta-Koeffizient (b1) in der logistischen Regressionsfunktion dem Logarithmus der Odds Ratios für diesen Prädiktor.

Wenn die Odds Ratio 2 ist, dann sind die Chancen, dass das Ereignis eintritt (Ereignis = 1), doppelt so hoch, wenn der Prädiktor x vorhanden ist (x = 1) als für ein Fehlen des Prädiktors (x = 0).

So beträgt beispielsweise der Regressionskoeffizient für BMI `r log_reg$coefficients[3]`. Dies deutet darauf hin, dass eine Erhöhung des BMI um 5 Einheiten die Wahrscheinlichkeit, an Diabetes erkrankt zu sein, um das `r exp(log_reg$coefficients[3])*5`-fache erhöht $\left(\exp(\beta_{\operatorname{BMI}})\cdot5\right)$.


### d)
```{r}
packageTest("pROC")

plot.roc(diab$diabetes, diab$pgc+diab$bmi)
```

### e)

```{r}
test <- NULL
test$y.true <- diab$diabetes
test$y.pred <- predict.glm(log_reg, type="response")

test$y.pred[test$y.pred > 0.5] = 1
test$y.pred[test$y.pred <= 0.5] = 0

confusion_matrix <- table(test)
confusion_matrix

misclass_rate <- 1-sum(diag(confusion_matrix))/sum(confusion_matrix)

sensitivity <- confusion_matrix[2,2]/(confusion_matrix[2,1] + confusion_matrix[2,2])

specificity <- confusion_matrix[1,1]/(confusion_matrix[1,1] + confusion_matrix[1,2])

misclass_rate
sensitivity
specificity

plot.roc(diab$diabetes, predict.glm(log_reg, type="response"))
points(specificity, sensitivity, col="red", pch = 16)
```

### f)
```{r}
packageTest("StatMeasures")
packageTest("ggplot2")

diab$prob <- predict.glm(log_reg, type="response")
diab$decile <- decile(diab$prob)

actual <- c()
predicted <- c()

for (decile in seq(1,10)){
  predicted <- append(predicted, length(diab$pregn[diab$decile == decile])
                      *mean(diab$prob[diab$decile == decile]))
  actual <- append(actual, length(diab$pregn[(diab$decile == decile) 
                                             & (diab$diabetes == 1)]))
}

decile_df <- data.frame(actual, predicted)
ggplot(aes(x=actual, y=predicted), data = decile_df) +
  geom_point() +
  geom_abline(slope=1, intercept=0, colour = 'darkgreen') +
  ggtitle("Dezile: Erwartete vs beobachtete Frauen mit Diabetes")
```

### g)
```{r}
ggplot(diab, aes(x=insulin)) + 
  geom_histogram(bins = 15) +
  ggtitle("Histogramm der Variable Insulin")

test <- NULL
test$log_insulin <- log1p(diab$insulin)
test <- as.data.frame(test)

ggplot(test, aes(x=log_insulin)) + 
  geom_histogram(bins = 15) +
  ggtitle("Histogramm der Variable log(1+Insulin)")

diab$log_insulin <- log1p(diab$insulin)

log_reg1 <- glm(diabetes~pgc+bmi+log_insulin, family=binomial(link='logit'), data=diab)

test <- NULL
test$y.true <- diab$diabetes
test$y.pred <- predict.glm(log_reg1, type="response")

test$y.pred[test$y.pred > 0.5] = 1
test$y.pred[test$y.pred <= 0.5] = 0

confusion_matrix <- table(test)
confusion_matrix

misclass_rate <- 1-sum(diag(confusion_matrix))/sum(confusion_matrix)

sensitivity <- confusion_matrix[2,2]/(confusion_matrix[2,1] + confusion_matrix[2,2])

specificity <- confusion_matrix[1,1]/(confusion_matrix[1,1] + confusion_matrix[1,2])

misclass_rate
sensitivity
specificity

plot.roc(diab$diabetes, predict.glm(log_reg1, type="response"))
```


## Aufgabe 3

```{r}
set.seed(222)
packageTest('class')

nor <-function(x) { (x -min(x))/(max(x)-min(x))   }
ran <- sample(1:nrow(diab), 0.5 * nrow(diab))
diab_norm <- as.data.frame(lapply(diab[,c(2,6)], nor))
#...oder alle Variablen zur Prognose?

train <- diab_norm[ran,]
test <- diab_norm[-ran,]

target_category <- diab[ran,8]
test_category <- diab[-ran,8]

knn1 <- knn(train,test,cl=target_category,k=1)
knn5 <- knn(train,test,cl=target_category,k=5)
knn10 <- knn(train,test,cl=target_category,k=10)

conf1 <- table(knn1,test_category)
conf5 <- table(knn5,test_category)
conf10 <- table(knn10,test_category)

error <- function(x){
  1 - sum(diag(x)/(sum(rowSums(x))))
}

error(conf1)
error(conf5)
error(conf10)
```